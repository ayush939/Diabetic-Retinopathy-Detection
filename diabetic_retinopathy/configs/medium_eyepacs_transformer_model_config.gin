# Input pipeline
load.name = 'eyepacs'
load.data_dir = "/home/RUS_CIP/st180270/datasets/"
#load.eyepacs_train_class0 = 6873
#load.eyepacs_val_class0 = 2056
#load.eyepacs_test_class0 = 8225
load.eyepacs_train_class0 = 2000
load.eyepacs_val_class0 = 2000
load.eyepacs_test_class0 = 2000
load.idrid_oversample_on = True
load.graham_preprocessing_on = True #True -> Graham Preprocessing is happening, False -> Graham Preprocessing is not happening

preprocess.img_height = 256
preprocess.img_width = 256
augment.data_aug_on = True #True -> Data Augmentation is on, False -> Data Augmentation is off
prepare.batch_size = 16
prepare.caching = False
    
# Training
Trainer.total_steps = 150000
Trainer.log_interval = 5000
Trainer.ckpt_interval = 5000
Trainer.learning_rate = 0.0001
Trainer.after_step_save = 50000

#Evaluation
evaluate.learning_rate = 0.0001
evaluate.run_paths = "latest_experiments/transformer_model/transformer_small_idrid/run_2023-01-25T16-35-49-624312/ckpts/ckpt_@step-130000"
evaluate.inp_img_path = "/home/RUS_CIP/st180270/datasets/IDRID_dataset/images/test/IDRiD_001.jpg"


#Grad_cam
superimpose_gradcam.img_path = "/home/RUS_CIP/st180270/datasets/IDRID_dataset/images/test/IDRiD_004.jpg"

# Architectures - Transformers
ViT_classifier.input_shape = (256, 256, 3)
ViT_classifier.transformer_backbone_trainable = True
ViT_classifier.MLP_head_trainable = True

transformer_backbone.input_sh = (256, 256, 3)
transformer_backbone.patch_size = 8
transformer_backbone.no_of_patches = 1024
# No_of_patches = (image_width/patch_size) * (image_height/patch_size)
transformer_backbone.proj_dim = 128
transformer_backbone.transformer_units = [256, 128]
#transformer_units = [proj_dim*2, proj_dim]
transformer_backbone.transformer_layers = 2
transformer_backbone.no_of_heads = 3
transformer_backbone.dropout_rate = 0.7
head.head_input_shape = (None, 128) 
head.mlp_head_units = [64]
head.dropout_rate = 0.7
head.no_of_classes = 1